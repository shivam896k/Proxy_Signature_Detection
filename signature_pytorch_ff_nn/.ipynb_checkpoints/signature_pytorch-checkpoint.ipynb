{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNCx8n0uA1Iu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbPV4ur8bpxt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUIwDKyCchMK"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m71ZtCThsmkU"
   },
   "outputs": [],
   "source": [
    "# folder_names = ['001','002','003','004','005','006','007','008','009','010','011','012','013','014','015','016','017','018','019','020','021','022','023','024','025','026','027','028','029','030','031','032','033','034','035','036','037','038','039','040','041','042','043','044','045','046','047','048','049','050','051','052','053','054','055','056','057','058','059','060','061','062','063','064','065','066','067','068','069','070','071','072','073','074','075','076','077','078','079','080','081','082','083','084','085','086','087','088','089','090','091','092','093','094','095','096','097','098','099','100',\n",
    "# '101','102','103','104','105','106','107','108','109','110','111','112','113','114','115','116','117','118','119','120','121','122','123','124','125','126','127','128','129','130','131','132','133','134','135','136','137','138','139','140','141','142','143','144','145','146','147','148','149','150','151','152','153','154','155','156','157','158','159','160','161','162','163','164','165','166','167','168','169','170','171','172','173','174','175','176','177','178','179','180','181','182','183','184','185','186','187','188','189','190','191','192','193','194','195','196','197','198','199','200']\n",
    "# folder_names = ['001','002','003','004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZsBZed4CqOy"
   },
   "outputs": [],
   "source": [
    "temporary_image = Image.open('/home/shivam/data/temp1/folder1/c-001-02.jpg')\n",
    "temporary_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icD4JOtPb1UW"
   },
   "outputs": [],
   "source": [
    "class ff_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ff_nn,self).__init__()\n",
    "        self.fc1 = nn.Linear(200*400,2)\n",
    "        self.fc2 = nn.Linear(2,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x # is not required you can directly use cross_entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BO4D2Mre59Y"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,root = '/home/shivam/data/temp1/folder1',transform = None):\n",
    "        self.root = root\n",
    "        self.files = os.listdir(root)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        self.file_name = self.files[index]\n",
    "        self.file_path = os.path.join(self.root,self.file_name)\n",
    "#         if self.file_path[-4:] == '.mat':      # this is done just to avoid the extra .mat file present in the folder\n",
    "#             temporary_image = Image.open('./drive/My Drive/Untitled folder/signature/001/c-001-01.jpg')\n",
    "#             reduced_size = 300,150\n",
    "#             temporary_image = temporary_image.resize(reduced_size, Image.ANTIALIAS)\n",
    "#             temporary_image = self.transform(temporary_image)\n",
    "#             return (temporary_image,-1)\n",
    "\n",
    "        self.target = 0\n",
    "        if(self.file_name[:2] == 'cf'):\n",
    "            self.target = 0\n",
    "        else:\n",
    "            self.target = 1\n",
    "        \n",
    "        image = Image.open(self.file_path)\n",
    "#         reduced_size = 300,150\n",
    "#         image = image.resize(reduced_size, Image.ANTIALIAS)\n",
    "        image = self.transform(image)\n",
    "        self.target = torch.tensor(self.target)\n",
    "        return (image, self.target)\n",
    "    \n",
    "    # you could try return target -1 if its a .mat file and if target == -1 then do not consider it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxfIGs0sCklf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_load_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fdab8621017b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mImageData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'home/shivam/data/temp1/folder1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_load_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fdab8621017b>\u001b[0m in \u001b[0;36mImageData\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mImageData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'home/shivam/data/temp1/folder1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_load_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_load_func' is not defined"
     ]
    }
   ],
   "source": [
    "class ImageData(Dataset):\n",
    "    def __init__(self, root='home/shivam/data/temp1/folder1', loader=image_load_func, transform=None):\n",
    "        self.root = root\n",
    "        self.files = os.listdir(self.root)\n",
    "        self.loader = loader\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.loader(os.path.join(self.root, self.files[index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hyo3rAWj0jWq"
   },
   "outputs": [],
   "source": [
    "folder_names = ['folder1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3_CWWFoGdud"
   },
   "outputs": [],
   "source": [
    "model = ff_nn()\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.1, momentum = 0.9)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HsJyCtQ-0nWP"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044de5f25feb4250b57beabfc65a663b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "fc2Wts = []\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "for folder in folder_names:\n",
    "    train_dataset = MyDataset('/home/shivam/data/temp1/{}/'.format(folder), transforms.ToTensor())\n",
    "#     image, target = train_dataset.__getitem__(0)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle = True, num_workers = 6)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "        for _,(image,label) in enumerate(train_loader):\n",
    "            image = Variable(image)\n",
    "            label = Variable(label)\n",
    "            image = image.view(-1, 200*400)\n",
    "            \n",
    "#             if(label == -1):\n",
    "#                 continue\n",
    "            output = model(image)   # output gives the probability distribution over the variables\n",
    "            loss = loss_function(output,label)\n",
    "            \n",
    "            \n",
    "#             final_output = output.data.max(1)[1]\n",
    "#             correct += final_output.eq(label.data).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "#             fc2Wts.append(list(model.fc2.parameters())[1])\n",
    "#         print(list(model.fc2.parameters())[1])\n",
    "        \n",
    "#         print('Loss = ',loss/54)\n",
    "    \n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "#     DataLoader(train_dataset,batch_size=54,shuffle = True,num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/home/shivam/data/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cQVK2HxS1K4"
   },
   "outputs": [],
   "source": [
    "for i in fc2Wts:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtxbLxIGQ_Is"
   },
   "outputs": [],
   "source": [
    "temp = model.fc2.parameters()\n",
    "fc2Wt = []\n",
    "for wts in temp:\n",
    "    fc2Wt.append(wts.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NnX49JKFRTS7",
    "outputId": "5ce4625c-4e28-40c0-d539-b46aa102cb07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-9.3775e+07,  2.5903e+04],\n",
       "        [ 9.3775e+07, -2.5904e+04]], requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.fc2.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "xcaSYl6bUczd",
    "outputId": "172b4f90-09f5-4156-b8b9-d3f61e499601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct :  tensor(36)\n",
      "len :  72\n",
      "Accuracy :  tensor(50)\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "fc2Wts = []\n",
    "\n",
    "folder_names = ['new']\n",
    "\n",
    "for folder in folder_names:\n",
    "    train_dataset = MyDataset('/home/shivam/data/temp1/{}/'.format(folder), transforms.ToTensor())\n",
    "    #     image, target = train_dataset.__getitem__(0)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=72, shuffle = True, num_workers = 6)\n",
    "\n",
    "    testLoss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    #     for epoch in tqdm_notebook(range(epochs)):\n",
    "    for _,(image, label) in enumerate(train_loader):\n",
    "        image = Variable(image)\n",
    "        label = Variable(label)\n",
    "        image = image.view(-1, 200*400)\n",
    "\n",
    "        predictedOutput = model(image)\n",
    "        testLoss += loss_function(predictedOutput,label)\n",
    "        \n",
    "        predictedDigit = predictedOutput.data.max(1)[1]\n",
    "        correct += predictedDigit.eq(label.data).sum()\n",
    "\n",
    "#         print(predictedDigit)\n",
    "    \n",
    "    print('correct : ', correct)\n",
    "    print('len : ', len(train_loader.dataset))\n",
    "    print('Accuracy : ',100 * correct/len(train_loader.dataset))\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "#     DataLoader(train_dataset,batch_size=54,shuffle = True,num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLTla8TK07yM"
   },
   "outputs": [],
   "source": [
    "\n",
    "# class ConcatDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, *datasets):\n",
    "#         self.datasets = datasets\n",
    "\n",
    "#     def __getitem__(self, i):\n",
    "#         return tuple(d[i] for d in self.datasets)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return min(len(d) for d in self.datasets)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#              ConcatDataset(\n",
    "#                  datasets.ImageFolder(traindir_A),\n",
    "#                  datasets.ImageFolder(traindir_B)\n",
    "#              ),\n",
    "#              batch_size=args.batch_size, shuffle=True,\n",
    "#              num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "# for i, (input, target) in enumerate(train_loader):\n",
    "#     ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOMhc3r3_a3J"
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset('/home/shivam/data/signature_data_csv/folder1/',transforms.ToTensor())\n",
    "image, target = train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "04HMuEEmMUV5",
    "outputId": "f40b4b0d-ee9a-4c32-b6e5-014460a00c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3MIN90o9_bmh"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "# type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKCeBbV6AGoT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "signature_pytorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
